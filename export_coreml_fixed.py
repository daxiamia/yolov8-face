#!/usr/bin/env python3
"""
YOLOv8-Face CoreML Export Script (Fixed for coremltools 8.3.0)

è¿™ä¸ªè„šæœ¬è§£å†³äº†coremltools 8.3.0ä¸­mlprogramæ ¼å¼çš„é—®é¢˜ã€‚
ç”¨æ³•: python export_coreml_fixed.py --model yolov8n-face.pt --imgsz 640
"""

import argparse
import sys
from pathlib import Path

try:
    from ultralytics import YOLO
    import torch
    import coremltools as ct
    import onnx
except ImportError as e:
    print(f"é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„è½¯ä»¶åŒ…ã€‚è¯·å®‰è£…ï¼š{e}")
    print("è¿è¡Œï¼špip install ultralytics coremltools onnx")
    sys.exit(1)


def fix_coreml_export(model_path, imgsz=640, int8=False):
    """
    ä¿®å¤CoreMLå¯¼å‡ºï¼Œé¿å…mlprogramæ ¼å¼é—®é¢˜
    """
    try:
        print(f"ğŸ”§ æ­£åœ¨ä¿®å¤CoreMLå¯¼å‡ºé—®é¢˜...")
        print(f"ğŸ“‚ åŠ è½½æ¨¡å‹ï¼š{model_path}")
        
        # åŠ è½½YOLOæ¨¡å‹
        model = YOLO(model_path)
        
        # ç¬¬ä¸€æ­¥ï¼šå¯¼å‡ºä¸ºONNXï¼ˆä¸­é—´æ ¼å¼ï¼‰
        print(f"ğŸ“¤ å¯¼å‡ºONNXæ¨¡å‹ï¼ˆå›¾åƒå¤§å°ï¼š{imgsz}ï¼‰...")
        onnx_path = model.export(format='onnx', imgsz=imgsz)
        print(f"âœ… ONNXæ¨¡å‹å·²åˆ›å»ºï¼š{onnx_path}")
        
        # ç¬¬äºŒæ­¥ï¼šä»ONNXè½¬æ¢ä¸ºCoreML
        print("ğŸ”„ ä»ONNXè½¬æ¢ä¸ºCoreML...")
        coreml_path = str(onnx_path).replace('.onnx', '.mlmodel')
        
        # è½¬æ¢ä¸ºCoreMLï¼Œä½¿ç”¨iOS14ç›®æ ‡é¿å…mlprogramé—®é¢˜
        print("ğŸ“± ä½¿ç”¨iOS14ç›®æ ‡è¿›è¡Œè½¬æ¢ï¼ˆé¿å…mlprogramæ ¼å¼é—®é¢˜ï¼‰...")
        
        # ç›´æ¥ä»ONNXæ–‡ä»¶è·¯å¾„è½¬æ¢ï¼Œè®©coremltoolsè‡ªåŠ¨æ£€æµ‹
        coreml_model = ct.convert(
            onnx_path,  # ç›´æ¥ä½¿ç”¨æ–‡ä»¶è·¯å¾„
            minimum_deployment_target=ct.target.iOS14,
            convert_to="neuralnetwork"  # å¼ºåˆ¶ä½¿ç”¨neural networkæ ¼å¼
        )
        
        # åº”ç”¨é‡åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if int8:
            print("âš¡ åº”ç”¨INT8é‡åŒ–...")
            coreml_model = ct.models.neural_network.quantization_utils.quantize_weights(
                coreml_model, 8, 'kmeans_lut'
            )
        
        # ä¿å­˜CoreMLæ¨¡å‹
        coreml_model.save(coreml_path)
        print(f"âœ… CoreMLæ¨¡å‹å·²ä¿å­˜ï¼š{coreml_path}")
        
        # æ¸…ç†ä¸­é—´æ–‡ä»¶
        try:
            Path(onnx_path).unlink()
            print("ğŸ§¹ å·²æ¸…ç†ä¸­é—´ONNXæ–‡ä»¶")
        except:
            pass
        
        # éªŒè¯æ¨¡å‹
        print("ğŸ” éªŒè¯CoreMLæ¨¡å‹...")
        try:
            # å°è¯•åŠ è½½æ¨¡å‹è¿›è¡ŒéªŒè¯
            test_model = ct.models.MLModel(coreml_path)
            print("âœ… æ¨¡å‹éªŒè¯æˆåŠŸï¼")
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯ï¼š")
            print(f"   - è¾“å…¥ï¼š{test_model.input_description}")
            print(f"   - è¾“å‡ºï¼š{test_model.output_description}")
            
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹éªŒè¯å¤±è´¥ï¼š{e}")
        
        return coreml_path
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥ï¼š{e}")
        print(f"\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®ï¼š")
        print(f"1. å°è¯•é™çº§coremltoolsç‰ˆæœ¬ï¼špip install coremltools==7.2")
        print(f"2. ç¡®ä¿ultralyticsæ˜¯æœ€æ–°ç‰ˆæœ¬ï¼špip install -U ultralytics") 
        print(f"3. å°è¯•æ›´å°çš„å›¾åƒå°ºå¯¸ï¼š--imgsz 320")
        print(f"4. æ£€æŸ¥PyTorchå…¼å®¹æ€§ï¼šå½“å‰ä½¿ç”¨çš„æ˜¯PyTorch {torch.__version__}")
        return None


def create_integration_guide(coreml_path):
    """åˆ›å»ºiOSé›†æˆæŒ‡å—"""
    if not coreml_path:
        return
        
    guide_content = f"""
# YOLOv8-Face iOSé›†æˆæŒ‡å—

## âœ… æˆåŠŸå¯¼å‡ºçš„æ¨¡å‹
- **æ¨¡å‹æ–‡ä»¶**: `{Path(coreml_path).name}`
- **æ ¼å¼**: CoreML Neural Network (å…¼å®¹iOS14+)
- **æ¨èiOSç‰ˆæœ¬**: iOS14.0+

## ğŸš€ å¿«é€Ÿé›†æˆæ­¥éª¤

### 1. æ·»åŠ æ¨¡å‹åˆ°Xcodeé¡¹ç›®
1. å°† `{Path(coreml_path).name}` æ‹–æ‹½åˆ°Xcodeé¡¹ç›®ä¸­
2. ç¡®ä¿æ·»åŠ åˆ°Targetçš„Bundle Resourcesä¸­

### 2. Swiftä»£ç ç¤ºä¾‹

```swift
import CoreML
import Vision
import UIKit

class FaceDetector {{
    private var model: VNCoreMLModel?
    
    init() {{
        loadModel()
    }}
    
    private func loadModel() {{
        guard let modelURL = Bundle.main.url(
            forResource: "{Path(coreml_path).stem}", 
            withExtension: "mlmodelc"
        ) else {{
            print("æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶")
            return
        }}
        
        do {{
            let mlModel = try MLModel(contentsOf: modelURL)
            self.model = try VNCoreMLModel(for: mlModel)
            print("æ¨¡å‹åŠ è½½æˆåŠŸ")
        }} catch {{
            print("æ¨¡å‹åŠ è½½å¤±è´¥: \\(error)")
        }}
    }}
    
    func detectFaces(in image: UIImage, completion: @escaping ([VNFaceObservation]) -> Void) {{
        guard let model = self.model,
              let cgImage = image.cgImage else {{
            completion([])
            return
        }}
        
        let request = VNCoreMLRequest(model: model) {{ request, error in
            guard let results = request.results as? [VNRecognizedObjectObservation] else {{
                completion([])
                return
            }}
            
            // å¤„ç†æ£€æµ‹ç»“æœ
            DispatchQueue.main.async {{
                completion([]) // è½¬æ¢ä¸ºVNFaceObservationæ ¼å¼
            }}
        }}
        
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        DispatchQueue.global(qos: .userInitiated).async {{
            try? handler.perform([request])
        }}
    }}
}}
```

## ğŸ“ ä½¿ç”¨è¯´æ˜

1. **å›¾åƒé¢„å¤„ç†**: ç¡®ä¿è¾“å…¥å›¾åƒå°ºå¯¸ä¸º {imgsz}x{imgsz}
2. **æ€§èƒ½ä¼˜åŒ–**: åœ¨åå°çº¿ç¨‹è¿è¡Œæ¨ç†ï¼Œé¿å…é˜»å¡UI
3. **å†…å­˜ç®¡ç†**: åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å›¾åƒå’Œç»“æœ
4. **é”™è¯¯å¤„ç†**: å¦¥å–„å¤„ç†æ¨¡å‹åŠ è½½å’Œæ¨ç†è¿‡ç¨‹ä¸­çš„å¼‚å¸¸

## ğŸ¯ æµ‹è¯•å»ºè®®

1. ä½¿ç”¨ä¸åŒå…‰ç…§æ¡ä»¶çš„äººè„¸å›¾åƒæµ‹è¯•
2. æµ‹è¯•å¤šäººè„¸åœºæ™¯
3. éªŒè¯åœ¨ä¸åŒiOSè®¾å¤‡ä¸Šçš„æ€§èƒ½è¡¨ç°

---
ç”Ÿæˆæ—¶é—´: {Path().cwd()}
æ¨¡å‹è·¯å¾„: {coreml_path}
"""

    guide_file = Path("iOS_Integration_Guide_Fixed.md")
    with open(guide_file, 'w', encoding='utf-8') as f:
        f.write(guide_content)
    
    print(f"ğŸ“– iOSé›†æˆæŒ‡å—å·²åˆ›å»ºï¼š{guide_file}")


def main():
    parser = argparse.ArgumentParser(description='ä¿®å¤CoreMLå¯¼å‡ºé—®é¢˜')
    parser.add_argument('--model', type=str, default='yolov8n-face.pt',
                        help='YOLOv8-Faceæ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--imgsz', type=int, default=640,
                        help='æ¨ç†å›¾åƒå°ºå¯¸ï¼ˆé»˜è®¤ï¼š640ï¼‰')
    parser.add_argument('--int8', action='store_true',
                        help='ä½¿ç”¨INT8é‡åŒ–å‡å°æ¨¡å‹å¤§å°')
    
    args = parser.parse_args()
    
    print("ğŸ§ª YOLOv8-Face CoreMLå¯¼å‡ºä¿®å¤å·¥å…·\n")
    print(f"ğŸ Pythonç‰ˆæœ¬: {sys.version}")
    print(f"âš¡ PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"ğŸ CoreMLToolsç‰ˆæœ¬: {ct.__version__}")
    print()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    model_path = Path(args.model)
    if not model_path.exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{args.model}")
        print("\nğŸ“¥ è¯·ä¸‹è½½YOLOv8-Faceæ¨¡å‹ï¼š")
        print("- yolov8-lite-t: https://drive.google.com/file/d/1vFMGW8xtRVo9bfC9yJVWWGY7vVxbLh94/view?usp=sharing")
        print("- yolov8-lite-s: https://drive.google.com/file/d/1ckpBT8KfwURTvTm5pa-cMC89A0V5jbaq/view?usp=sharing") 
        print("- yolov8n: https://drive.google.com/file/d/1qcr9DbgsX3ryrz2uU8w4Xm3cOrRywXqb/view?usp=sharing")
        return
    
    # æ‰§è¡Œä¿®å¤å¯¼å‡º
    coreml_path = fix_coreml_export(str(model_path), args.imgsz, args.int8)
    
    if coreml_path:
        # åˆ›å»ºé›†æˆæŒ‡å—
        create_integration_guide(coreml_path)
        
        print(f"\nğŸ‰ å¯¼å‡ºå®Œæˆï¼")
        print(f"ğŸ“± CoreMLæ¨¡å‹: {coreml_path}")
        print(f"ğŸ“š é›†æˆæŒ‡å—: iOS_Integration_Guide_Fixed.md")
        
        # æ˜¾ç¤ºä¸‹ä¸€æ­¥
        print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥ï¼š")
        print(f"1. å°† {Path(coreml_path).name} æ·»åŠ åˆ°ä½ çš„iOSé¡¹ç›®")
        print(f"2. æŒ‰ç…§é›†æˆæŒ‡å—å®ç°äººè„¸æ£€æµ‹åŠŸèƒ½")
        print(f"3. åœ¨iOSè®¾å¤‡ä¸Šæµ‹è¯•æ€§èƒ½")
    else:
        print(f"\nâŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main() 